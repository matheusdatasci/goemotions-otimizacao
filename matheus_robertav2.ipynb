{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN7Vf8vZHOW9"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import RobertaForSequenceClassification\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oel_KHCINsS"
      },
      "outputs": [],
      "source": [
        "#carregando o dataset go_emotions do HuggingFace\n",
        "dataset_raw = load_dataset('google-research-datasets/go_emotions', 'raw')['train'].shuffle(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l73JqGUe0ZiK"
      },
      "outputs": [],
      "source": [
        "dataset_val = dataset_raw.select(range(6000))\n",
        "dataset_treino = dataset_raw.select(range(6000, 176000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aeofmov5w67l"
      },
      "outputs": [],
      "source": [
        "len(dataset_treino), len(dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIybZ6whLDVK"
      },
      "outputs": [],
      "source": [
        "dataset_val[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kwZ8HWU8UyB"
      },
      "outputs": [],
      "source": [
        "emocoes = ['admiration','amusement','anger','annoyance','approval','caring',\n",
        "    'confusion','curiosity','desire','disappointment','disapproval','disgust',\n",
        "    'embarrassment','excitement','fear','gratitude','grief','joy','love',\n",
        "    'nervousness','optimism','pride','realization','relief','remorse',\n",
        "    'sadness','surprise','neutral']\n",
        "\n",
        "\n",
        "colunas_necessarias = ['text'] + emocoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pbia8K_8b8o"
      },
      "outputs": [],
      "source": [
        "dataset_treino = dataset_treino.remove_columns([c for c in dataset_treino.column_names if c not in colunas_necessarias])\n",
        "dataset_val = dataset_val.remove_columns([c for c in dataset_val.column_names if c not in colunas_necessarias])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA-XIMadKxjA"
      },
      "outputs": [],
      "source": [
        "#instaciando o tokenizer do modelo e criando uma função para tokenizar os dados em batches\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenizer_batch(batch):\n",
        "  return tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "silTN9r5LsRL"
      },
      "outputs": [],
      "source": [
        "#tokenizando os textos dos três conjuntos\n",
        "dataset_treino = dataset_treino.map(tokenizer_batch, batched=True)\n",
        "dataset_val = dataset_val.map(tokenizer_batch, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLhY7LdWNeHP"
      },
      "outputs": [],
      "source": [
        "#criando labels no formato que o modelo deve receber\n",
        "def criar_labels(dados):\n",
        "    dados['labels'] = [dados[col] for col in emocoes]\n",
        "    return dados\n",
        "\n",
        "dataset_treino = dataset_treino.map(criar_labels)\n",
        "dataset_val    = dataset_val.map(criar_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VUS3rZENt4u",
        "outputId": "e76f7ce3-8682-472d-8d76-92c4a44e3a1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_val[0]['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KuQ3lQKNHjZ"
      },
      "outputs": [],
      "source": [
        "#passando os dados do dataset para tensores\n",
        "colunas_modelo = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "\n",
        "dataset_treino.set_format(\"torch\", columns=colunas_modelo)\n",
        "dataset_val.set_format(\"torch\", columns=colunas_modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyHk6VSCk1u2"
      },
      "outputs": [],
      "source": [
        "#defindo os batches\n",
        "batch_treino = DataLoader(dataset_treino, batch_size=32, shuffle=True)\n",
        "batch_validacao = DataLoader(dataset_val, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbLyW54mON-r"
      },
      "outputs": [],
      "source": [
        "#treinamento do modelo\n",
        "modelo = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=28, problem_type=\"multi_label_classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaAk0AQohhai"
      },
      "outputs": [],
      "source": [
        "#passando o modelo para rodar na GPU, pois vamos usar uma GPU T4 para o fine-tuning\n",
        "gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJYg0tBpkEIU"
      },
      "outputs": [],
      "source": [
        "#adicionando o modelo ao compilador JIT\n",
        "modelo = torch.compile(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kefgn6Z1hhn4"
      },
      "outputs": [],
      "source": [
        "#instaciando o otimizador\n",
        "otimizador = AdamW(modelo.parameters(), lr=2e-5, fused=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3kKtpoujBwE"
      },
      "outputs": [],
      "source": [
        "#treinamento do modelo: 5 epocas com batch size de 32, ou seja, a cada 32 amostras o modelo atualiza os pesos.\n",
        "epocas = 5\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoca in range(epocas):\n",
        "    modelo.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(batch_treino, desc=f\"Época {epoca+1}/{epocas}\", leave=False):\n",
        "        ids = batch[\"input_ids\"].to(gpu)\n",
        "        mask = batch[\"attention_mask\"].to(gpu)\n",
        "        labels = batch[\"labels\"].to(gpu).float()\n",
        "\n",
        "        otimizador.zero_grad()\n",
        "        with autocast(device_type='cuda'):\n",
        "            output = modelo(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            loss = output.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(otimizador)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    perda_treino = total_loss / len(batch_treino)\n",
        "    print(f\"Época {epoca+1}/{epocas} | Perda média treino: {perda_treino:.4f}\")\n",
        "\n",
        "    modelo.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in batch_validacao:\n",
        "            ids = batch[\"input_ids\"].to(gpu)\n",
        "            mask = batch[\"attention_mask\"].to(gpu)\n",
        "            labels = batch[\"labels\"].to(gpu).float()\n",
        "\n",
        "            output = modelo(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            val_loss += output.loss.item()\n",
        "\n",
        "    perda_val = val_loss / len(batch_validacao)\n",
        "    print(f\"Perda média validação: {perda_val:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-kQEJJLsBnu"
      },
      "outputs": [],
      "source": [
        "modelo.eval()\n",
        "todas_pred = []\n",
        "todas_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in batch_validacao:\n",
        "        inputs = batch['input_ids'].to(gpu)\n",
        "        labels = batch['labels'].to(gpu)\n",
        "\n",
        "        outputs = modelo(inputs)\n",
        "        preds = torch.sigmoid(outputs.logits)\n",
        "        preds = (preds > 0.3).int()\n",
        "\n",
        "        todas_pred.extend(preds.cpu().numpy())\n",
        "        todas_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(todas_labels, todas_pred, average='samples')\n",
        "acuracia = accuracy_score(todas_labels, todas_pred)\n",
        "\n",
        "print(\"F1 (multi-label, average='samples'):\", f1)\n",
        "print(\"Accuracy (multi-label exact match):\", acuracia)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}